

<!DOCTYPE html>

<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  

  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="/assets/css/just-the-docs-default.css">

  

  
    <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Optimizers and Regularizers (IDL3) | My Projects</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Optimizers and Regularizers (IDL3)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Computer Vision projects and assignments during my time in CMU" />
<meta property="og:description" content="Computer Vision projects and assignments during my time in CMU" />
<link rel="canonical" href="http://localhost:4000/docs/DL_Overview/IDL3.html" />
<meta property="og:url" content="http://localhost:4000/docs/DL_Overview/IDL3.html" />
<meta property="og:site_name" content="My Projects" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Optimizers and Regularizers (IDL3)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Computer Vision projects and assignments during my time in CMU","headline":"Optimizers and Regularizers (IDL3)","url":"http://localhost:4000/docs/DL_Overview/IDL3.html"}</script>
<!-- End Jekyll SEO tag -->


  

</head>

<body>
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-link" viewBox="0 0 24 24">
      <title>Link</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
        <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
      </svg>
    </symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
      <title>Search</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
        <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
      </svg>
    </symbol>
    <symbol id="svg-menu" viewBox="0 0 24 24">
      <title>Menu</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
        <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
      </svg>
    </symbol>
    <symbol id="svg-arrow-right" viewBox="0 0 24 24">
      <title>Expand</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
        <polyline points="9 18 15 12 9 6"></polyline>
      </svg>
    </symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
      <title>Document</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
        <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
      </svg>
    </symbol>
  </svg>

  <div class="side-bar">
    <div class="site-header">
      <a href="http://localhost:4000/" class="site-title lh-tight">
  My Projects

</a>
      <a href="#" id="menu-button" class="site-button">
        <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg>
      </a>
    </div>
    <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
      
        <ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="http://localhost:4000/intro/" class="nav-list-link">Building this Page</a></li><li class="nav-list-item"><a href="http://localhost:4000/numpy/" class="nav-list-link">Numpy</a></li><li class="nav-list-item"><a href="http://localhost:4000/spatial_pyramid_matching/" class="nav-list-link">Spatial Pyramid Matching for Scene Classification</a></li><li class="nav-list-item"><a href="http://localhost:4000/optical_flow/" class="nav-list-link">Optical Flow and Image Alignment</a></li><li class="nav-list-item"><a href="http://localhost:4000/planar_homography/" class="nav-list-link">Planar Homography</a></li><li class="nav-list-item"><a href="http://localhost:4000/3D_reconstruction/" class="nav-list-link">3D_reconstruction</a></li><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/DL_overview" class="nav-list-link">DL Overview</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/DL_Overview/DL.html" class="nav-list-link">Deep Learning Starter</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/DL_Overview/DL_old_arches.html" class="nav-list-link">DL Simple Architechtures</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/DL_Overview/IDL1.html" class="nav-list-link">MLPs (IDL1)</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/DL_Overview/IDL2.html" class="nav-list-link">Classifiers (IDL2)</a></li><li class="nav-list-item  active"><a href="http://localhost:4000/docs/DL_Overview/IDL3.html" class="nav-list-link active">Optimizers and Regularizers (IDL3)</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/DL_Overview/IDL4.html" class="nav-list-link">Intro to CNNs</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/DL_Overview/Resnet.html" class="nav-list-link">RESNET</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/Intro%20to%20ML" class="nav-list-link">Intro to ML</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/Intro%20to%20ML/Basics.html" class="nav-list-link">Basics</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Intro%20to%20ML/Linear_Regression.html" class="nav-list-link">Linear Regression</a></li></ul></li><li class="nav-list-item"><a href="http://localhost:4000/pytorch/" class="nav-list-link">Intro to Pytorch</a></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/SLAM" class="nav-list-link">SLAM</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/Probability_review.html" class="nav-list-link">Recap on Probability</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/Expectation_and_cov.html" class="nav-list-link">Expectation and Covariance</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/Particle%20Filter_theory.html" class="nav-list-link">Particle Filters Theory</a></li></ul></li><li class="nav-list-item"><a href="http://localhost:4000/camera_model/" class="nav-list-link">Camera Models</a></li><li class="nav-list-item"><a href="http://localhost:4000/git_concepts" class="nav-list-link">Git Concepts</a></li></ul>

      
    </nav>
    <footer class="site-footer">
      This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
    </footer>
  </div>
  <div class="main" id="top">
    <div id="main-header" class="main-header">
      
        <div class="search">
          <div class="search-input-wrap">
            <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search My Projects" aria-label="Search My Projects" autocomplete="off">
            <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
          </div>
          <div id="search-results" class="search-results"></div>
        </div>
      
      
      
        <nav aria-label="Auxiliary" class="aux-nav">
          <ul class="aux-nav-list">
            
              <li class="aux-nav-list-item">
                <a href="//github.com/sushanthj" class="site-button"
                  
                >
                  Sushanth Jayanth's github
                </a>
              </li>
            
          </ul>
        </nav>
      
    </div>
    <div id="main-content-wrap" class="main-content-wrap">
      
        <nav aria-label="Breadcrumb" class="breadcrumb-nav">
            <ol class="breadcrumb-nav-list">
              
                <li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/DL_overview">DL Overview</a></li>
              
              <li class="breadcrumb-nav-list-item"><span>Optimizers and Regularizers (IDL3)</span></li>
            </ol>
          </nav>
        
      
      <div id="main-content" class="main-content" role="main">
        
          <details open="">
  <summary>
    Table of contents
  {: .text-delta }
  </summary>
<ol id="markdown-toc">
  <li><a href="#before-you-begin" id="markdown-toc-before-you-begin">Before you Begin</a></li>
  <li><a href="#improving-over-momentum-update" id="markdown-toc-improving-over-momentum-update">Improving over momentum update</a>    <ol>
      <li><a href="#commonly-used-methods-which-use-second-moment" id="markdown-toc-commonly-used-methods-which-use-second-moment">Commonly Used methods which use Second Moment</a>        <ol>
          <li><a href="#rms-prop" id="markdown-toc-rms-prop">RMS Prop</a></li>
          <li><a href="#adam-rmsprop-with-momentum" id="markdown-toc-adam-rmsprop-with-momentum">ADAM (RMSprop with momentum)</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#batch-normalization" id="markdown-toc-batch-normalization">Batch Normalization</a>    <ol>
      <li><a href="#problem-with-covarite-shifts" id="markdown-toc-problem-with-covarite-shifts">Problem with covarite shifts</a></li>
      <li><a href="#solution-to-covariate-shifts" id="markdown-toc-solution-to-covariate-shifts">Solution to covariate shifts</a></li>
      <li><a href="#batch-norm-theory" id="markdown-toc-batch-norm-theory">Batch Norm Theory</a></li>
      <li><a href="#backprop-through-batch-norm" id="markdown-toc-backprop-through-batch-norm">Backprop through Batch Norm</a>        <ol>
          <li><a href="#derivation" id="markdown-toc-derivation">Derivation</a></li>
        </ol>
      </li>
      <li><a href="#batch-norm-in-test-time" id="markdown-toc-batch-norm-in-test-time">Batch Norm in Test Time</a></li>
    </ol>
  </li>
  <li><a href="#overfitting" id="markdown-toc-overfitting">Overfitting</a>    <ol>
      <li><a href="#smoothness-through-weight-manipulation" id="markdown-toc-smoothness-through-weight-manipulation">Smoothness through weight manipulation</a></li>
      <li><a href="#smoothness-through-weight-constraints-regularization" id="markdown-toc-smoothness-through-weight-constraints-regularization">Smoothness through weight constraints (Regularization)</a></li>
      <li><a href="#smoothness-through-network-structure" id="markdown-toc-smoothness-through-network-structure">Smoothness through network structure</a>        <ol>
          <li><a href="#example-for-further-clarity" id="markdown-toc-example-for-further-clarity">Example for further clarity</a></li>
        </ol>
      </li>
      <li><a href="#dropout" id="markdown-toc-dropout">Dropout</a>        <ol>
          <li><a href="#implementing-dropout-during-training" id="markdown-toc-implementing-dropout-during-training">Implementing Dropout during Training</a></li>
          <li><a href="#implementing-dropout-during-inference" id="markdown-toc-implementing-dropout-during-inference">Implementing Dropout during Inference</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#augmentation" id="markdown-toc-augmentation">Augmentation</a></li>
  <li><a href="#other-tricks" id="markdown-toc-other-tricks">Other Tricks</a></li>
</ol>

</details>
      <h2 id="before-you-begin">
        
        
          <a href="#before-you-begin" class="anchor-heading" aria-labelledby="before-you-begin"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Before you Begin
        
        
      </h2>
    

<p><a href="https://www.youtube.com/watch?v=fMie0uWwzDQ&amp;list=PLp-0K3kfddPzCnS4CqKphh-zT3aDwybDe&amp;index=15&amp;ab_channel=CarnegieMellonUniversityDeepLearning" class="btn fs-3 mb-4 mb-md-0">Ref: 11-785</a></p>
      <h1 id="improving-over-momentum-update">
        
        
          <a href="#improving-over-momentum-update" class="anchor-heading" aria-labelledby="improving-over-momentum-update"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Improving over momentum update
        
        
      </h1>
    

<p>Previously we saw how the derivatives change in subsequent steps (as we did in simple
momentum) and take a step considering the weighted average of the current and prior step
(actual implementation was a running average)</p>

<p>Now, we’ll consider the way in which these derivatives change (this is called second moment)
which takes care of the variance in graident shifts.</p>

<p><img src="/images/IDL3/momentum1.png" alt="" /></p>

<p>The second moment can be implemented as shown below. As seen in our prior image, since we had
high variation along y and low variation along x, we will do:</p>

<p><img src="/images/IDL3/momentum2.png" alt="" /></p>
      <h2 id="commonly-used-methods-which-use-second-moment">
        
        
          <a href="#commonly-used-methods-which-use-second-moment" class="anchor-heading" aria-labelledby="commonly-used-methods-which-use-second-moment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Commonly Used methods which use Second Moment
        
        
      </h2>
    
      <h3 id="rms-prop">
        
        
          <a href="#rms-prop" class="anchor-heading" aria-labelledby="rms-prop"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> RMS Prop
        
        
      </h3>
    

<p>Here, let’s do a running average like simple momentum, but do it on the second derivative
of the gradient. The gamma value is just a weighting factor between prior step’s gradient (k-1)
and (1-gamma) is the weight applied to the current step’s gradient:</p>

<p><img src="/images/IDL3/rmsprop1.png" alt="" /></p>

<p>Now, the way we will include this is our update will be to normalize the learning rate using
this second second moement:</p>

<p><img src="/images/IDL3/rmsprop2.png" alt="" /></p>

<p>Just for comparison, this is how the update step for simple momentum only scaled the preious
step’s weight magnitude and did not touch learning rate.</p>

<p><img src="/images/IDL2/Convergence16.png" alt="" /></p>
      <h3 id="adam-rmsprop-with-momentum">
        
        
          <a href="#adam-rmsprop-with-momentum" class="anchor-heading" aria-labelledby="adam-rmsprop-with-momentum"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ADAM (RMSprop with momentum)
        
        
      </h3>
    

<p><img src="/images/IDL3/adam1.png" alt="" /></p>

<p>The reason first and second moments are scaled by the weighting factor is to ensure that
in the beginning of training, we don’t let sigma and gamma terms to dominate 
(it’ll slow us down)</p>

<p><img src="/images/IDL3/adam3.png" alt="" /></p>
      <h1 id="batch-normalization">
        
        
          <a href="#batch-normalization" class="anchor-heading" aria-labelledby="batch-normalization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Batch Normalization
        
        
      </h1>
    
      <h3 id="problem-with-covarite-shifts">
        
        
          <a href="#problem-with-covarite-shifts" class="anchor-heading" aria-labelledby="problem-with-covarite-shifts"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Problem with covarite shifts
        
        
      </h3>
    

<p><img src="/images/IDL3/covshfit1.png" alt="" /></p>

<p><img src="/images/IDL3/covshift2.png" alt="" /></p>
      <h3 id="solution-to-covariate-shifts">
        
        
          <a href="#solution-to-covariate-shifts" class="anchor-heading" aria-labelledby="solution-to-covariate-shifts"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Solution to covariate shifts
        
        
      </h3>
    

<p><img src="/images/IDL3/covshift3.png" alt="" /></p>
      <h2 id="batch-norm-theory">
        
        
          <a href="#batch-norm-theory" class="anchor-heading" aria-labelledby="batch-norm-theory"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Batch Norm Theory
        
        
      </h2>
    

<ul>
  <li>We do this covariate shifts typically at the at location of the affine sum (Wx + b)</li>
  <li><img src="/images/IDL3/batch_norm1.png" alt="" /></li>
  <li><img src="/images/IDL3/batch_norm2.png" alt="" /></li>
  <li>The above step (first yellow box) will cause all training instances to have mean = 0 and variance = 1</li>
  <li>Now, we move the entire data to a separate appropriate location (second yellow box)
as defined by gamma and beta.</li>
  <li>How do we get this gamma and beta?
Ans. <img src="/images/IDL4/batch_norm_extra.png" alt="" /></li>
</ul>

<p>Q. Why is batch_norm applied before the activation function?
Ans. It’s debatable. But if it’s used after activation some activations may get
reveresed maybe?</p>

<p>Note. Understand vocab: Difference between Normalization and Standardization</p>

<p><img src="/images/IDL4/norm_v_stand.png" alt="" /></p>

<p>Now, its nice to see data having low variance. However, the real issue arises when we try
to do backprop.</p>
      <h2 id="backprop-through-batch-norm">
        
        
          <a href="#backprop-through-batch-norm" class="anchor-heading" aria-labelledby="backprop-through-batch-norm"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Backprop through Batch Norm
        
        
      </h2>
    

<p>Conventional backprop happens by taking a derivative of the divergence function as shown below:</p>

<p><img src="/images/IDL3/batch_norm3.png" alt="" /></p>

<p><strong>However, after batch norm, it gets tricky since our divergence will now depend on 
not only the mini-batch (training samples of mini-batch), but will now also depend on
the mean and variance of the entire mini-batch (since our mini-batch was scaled and shifted
according to the mean and variance)</strong></p>

<p><img src="/images/IDL3/batch_norm4.png" alt="" /></p>

<p><img src="/images/IDL3/batch_norm6.png" alt="" /></p>

<p><img src="/images/IDL3/batch_norm5.png" alt="" /></p>
      <h3 id="derivation">
        
        
          <a href="#derivation" class="anchor-heading" aria-labelledby="derivation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Derivation
        
        
      </h3>
    

<p>The derivation is shown below:</p>

<p><img src="/images/IDL3/bbatch1.jpg" alt="" />
<img src="/images/IDL3/bbatch2.jpg" alt="" />
<img src="/images/IDL3/bbatch3.jpg" alt="" />
<img src="/images/IDL3/bbatch4.jpg" alt="" />
<img src="/images/IDL3/bbatch5.jpg" alt="" />
<img src="/images/IDL3/bbatch6.jpg" alt="" />
<img src="/images/IDL3/bbatch7.jpg" alt="" />
<img src="/images/IDL3/bbatch8.jpg" alt="" />
<img src="/images/IDL3/bbatch9.jpg" alt="" /></p>
      <h2 id="batch-norm-in-test-time">
        
        
          <a href="#batch-norm-in-test-time" class="anchor-heading" aria-labelledby="batch-norm-in-test-time"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Batch Norm in Test Time
        
        
      </h2>
    

<p>Here also we need some estimate of variance as to where this test image belongs to.
We do so by using a running average over the training batches.</p>

<p><img src="/images/IDL3/batch_norm7.png" alt="" /></p>
      <h1 id="overfitting">
        
        
          <a href="#overfitting" class="anchor-heading" aria-labelledby="overfitting"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Overfitting
        
        
      </h1>
    

<p><img src="/images/IDL3/ofit1.png" alt="" /></p>

<p>We essentially need a way to smoothen the above curve such that it fills in the gap nicely.</p>

<p>There are several ways of doing this, but the most common ones are:</p>
      <h2 id="smoothness-through-weight-manipulation">
        
        
          <a href="#smoothness-through-weight-manipulation" class="anchor-heading" aria-labelledby="smoothness-through-weight-manipulation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Smoothness through weight manipulation
        
        
      </h2>
    

<p>Think of the sigmoid function <br />
<img src="/images/IDL3/ofit2.png" alt="" /></p>

<p>Now, if the value of our input (x) increases a lot, the curve changes from a nice
smooth curve to something a lot more steep:</p>

<p><img src="/images/IDL3/ofit3.png" alt="" />
(here w = our input (x))</p>

<p><strong>Therefore simply constraining the weight to be low will ensure the perceptron output is
smooth.</strong></p>
      <h2 id="smoothness-through-weight-constraints-regularization">
        
        
          <a href="#smoothness-through-weight-constraints-regularization" class="anchor-heading" aria-labelledby="smoothness-through-weight-constraints-regularization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Smoothness through weight constraints (Regularization)
        
        
      </h2>
    

<p>This is basically regularization (where we ensure model is penalized for large weights)</p>

<p><img src="/images/IDL3/ofit4.png" alt="" /></p>

<p>Now, this is also easy to backprop as shown below:</p>

<p><img src="/images/IDL3/ofit5.png" alt="" /></p>
      <h2 id="smoothness-through-network-structure">
        
        
          <a href="#smoothness-through-network-structure" class="anchor-heading" aria-labelledby="smoothness-through-network-structure"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Smoothness through network structure
        
        
      </h2>
    

<ul>
  <li>
    <p>As we saw in the MLP section on why depth matters, each layer of an MLP imposes
constraints, i.e. each layer creates some decision boundary.</p>
  </li>
  <li>
    <p>See <a href="https://sush-vision-projects.herokuapp.com/docs/DL_Overview/IDL1.html#why-do-we-need-depth">why we need depth</a></p>
  </li>
  <li>
    <p>In the picture below, after the first layer, we know that our input is in either
a pentagon region of a triangle region (<strong>but we don’t know where inside it!</strong>)</p>
  </li>
  <li>
    <p><img src="/images/IDL3/ofit6.png" alt="" /></p>
  </li>
  <li>
    <p>Therefore, deeper models have a natural tendency to restricting shapes they can model
and this gives the natural smoothness required.</p>
  </li>
</ul>
      <h3 id="example-for-further-clarity">
        
        
          <a href="#example-for-further-clarity" class="anchor-heading" aria-labelledby="example-for-further-clarity"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Example for further clarity
        
        
      </h3>
    

<p><img src="/images/IDL3/ofit7.png" alt="" /></p>

<p>In the above example, the earlier layers have really bad fit shapes. As we go deeper
the smoothness naturally increased.</p>
      <h2 id="dropout">
        
        
          <a href="#dropout" class="anchor-heading" aria-labelledby="dropout"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Dropout
        
        
      </h2>
    

<ul>
  <li>
    <p>During Train time, each neuron is active such that: <br />
(number_of_instances_neuron_is_active/total_number_of_instances) = alpha</p>

    <p>i.e. if the chance of a neuron being active is say 0.7 (then alpha = 0.7)</p>
  </li>
  <li>
    <p><img src="/images/IDL3/ofit9.png" alt="" /></p>
  </li>
  <li>
    <p><strong>By following above steps, The effective network is different for different sets of inputs.
Additionally, the graidents are also updated differently</strong></p>
  </li>
  <li>
    <p>Like any Bernoulli Distribution, each event has 2 outcomes. Therefore a statistical 
interpretation would yield the below picture:</p>
  </li>
  <li>
    <p><img src="/images/IDL3/ofit10.png" alt="" /></p>
  </li>
  <li>
    <p>I think it also serves as a form of augmentation, where instead of blacking out certain
parts of the image, we make the object recognizable only at certain receptive fields</p>
  </li>
  <li>
    <p>Dropout also has the tendency of removing redundancies in learning. i.e. the network 
learns a cat even if it doesn’t have a tail, or if it doens’t have pointy ears</p>
  </li>
</ul>
      <h3 id="implementing-dropout-during-training">
        
        
          <a href="#implementing-dropout-during-training" class="anchor-heading" aria-labelledby="implementing-dropout-during-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementing Dropout during Training
        
        
      </h3>
    

<p>The dropout is added onto the activation layer as an additional (like an if condition) constraint. It is shown below</p>

<p><img src="/images/IDL3/ofit11.png" alt="" /></p>

<p><strong>Now, we will use this alpha value in our test time everywhere</strong></p>
      <h3 id="implementing-dropout-during-inference">
        
        
          <a href="#implementing-dropout-during-inference" class="anchor-heading" aria-labelledby="implementing-dropout-during-inference"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementing Dropout during Inference
        
        
      </h3>
    

<ol>
  <li>We could add alpha (the bernoulli factor) to the activation of every neuron (just like train time)</li>
  <li>Or we could mulltiply every weight with alpha (we will effectively be blocking out connections instead of neurons)</li>
  <li><strong>Instead of applying alpha as chance of a neuron being active during train time, use
inverse of alpha. Then during test time, we just don’t use alpha at all!!</strong></li>
</ol>

<p><img src="/images/IDL3/ofit13.png" alt="" /></p>
      <h1 id="augmentation">
        
        
          <a href="#augmentation" class="anchor-heading" aria-labelledby="augmentation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Augmentation
        
        
      </h1>
    

<ol>
  <li>Mosaicing</li>
  <li>Flipping</li>
  <li>Rotating</li>
  <li>Blurring</li>
  <li>Warp (Distort the image)</li>
</ol>
      <h1 id="other-tricks">
        
        
          <a href="#other-tricks" class="anchor-heading" aria-labelledby="other-tricks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Other Tricks
        
        
      </h1>
    
<ol>
  <li>Normalize the input (covariate shifts in next section)</li>
  <li>Xavier Initialization</li>
</ol>

        

        

        
        
          <hr>
          <footer>
            

            <p class="text-small text-grey-dk-100 mb-0"></p>

            
              <div class="d-flex mt-2">
                
                
              </div>
            
          </footer>
        

      </div>
    </div>

    
      

      <div class="search-overlay"></div>
    
  </div>
</body>
</html>

