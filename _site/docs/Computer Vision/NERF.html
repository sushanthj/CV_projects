

<!DOCTYPE html>

<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  

  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon">

  <link rel="stylesheet" href="/assets/css/just-the-docs-default.css">

  

  
    <script type="text/javascript" src="/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Volume Rendering and NERFs | Navigating Robotics</title>
<meta name="generator" content="Jekyll v4.2.2" />
<meta property="og:title" content="Volume Rendering and NERFs" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Projects and assignments during my time in CMU" />
<meta property="og:description" content="Projects and assignments during my time in CMU" />
<link rel="canonical" href="http://localhost:4000/docs/Computer%20Vision/NERF.html" />
<meta property="og:url" content="http://localhost:4000/docs/Computer%20Vision/NERF.html" />
<meta property="og:site_name" content="Navigating Robotics" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Volume Rendering and NERFs" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Projects and assignments during my time in CMU","headline":"Volume Rendering and NERFs","url":"http://localhost:4000/docs/Computer%20Vision/NERF.html"}</script>
<!-- End Jekyll SEO tag -->


  

</head>

<body>
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
    <symbol id="svg-link" viewBox="0 0 24 24">
      <title>Link</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
        <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
      </svg>
    </symbol>
    <symbol id="svg-search" viewBox="0 0 24 24">
      <title>Search</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
        <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
      </svg>
    </symbol>
    <symbol id="svg-menu" viewBox="0 0 24 24">
      <title>Menu</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
        <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
      </svg>
    </symbol>
    <symbol id="svg-arrow-right" viewBox="0 0 24 24">
      <title>Expand</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
        <polyline points="9 18 15 12 9 6"></polyline>
      </svg>
    </symbol>
    <symbol id="svg-doc" viewBox="0 0 24 24">
      <title>Document</title>
      <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
        <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
      </svg>
    </symbol>
  </svg>

  <div class="side-bar">
    <div class="site-header">
      <a href="http://localhost:4000/" class="site-title lh-tight">
  Navigating Robotics

</a>
      <a href="#" id="menu-button" class="site-button">
        <svg viewBox="0 0 24 24" class="icon"><use xlink:href="#svg-menu"></use></svg>
      </a>
    </div>
    <nav role="navigation" aria-label="Main" id="site-nav" class="site-nav">
      
        <ul class="nav-list"><li class="nav-list-item"><a href="http://localhost:4000/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="http://localhost:4000/intro/" class="nav-list-link">Building this Page</a></li><li class="nav-list-item"><a href="http://localhost:4000/planar_homography/" class="nav-list-link">Planar Homography</a></li><li class="nav-list-item"><a href="http://localhost:4000/3D_reconstruction/" class="nav-list-link">3D Reconstruction</a></li><li class="nav-list-item"><a href="http://localhost:4000/optical_flow/" class="nav-list-link">Optical Flow and Image Alignment</a></li><li class="nav-list-item"><a href="http://localhost:4000/constr_rrt/" class="nav-list-link">Constrained RRT</a></li><li class="nav-list-item"><a href="http://localhost:4000/ConvNext/" class="nav-list-link">Rebuilding ConvNext</a></li><li class="nav-list-item"><a href="http://localhost:4000/mrsd_proj/" class="nav-list-link">MRSD Capstone Project</a></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/Deep%20Learning" class="nav-list-link">Deep Learning</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/Deep%20Learning/Basics.html" class="nav-list-link">ML Basics</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Deep%20Learning/DL.html" class="nav-list-link">Deep Learning Starter</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Deep%20Learning/IDL1.html" class="nav-list-link">MLPs (IDL1)</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Deep%20Learning/IDL2.html" class="nav-list-link">Classifiers (IDL2)</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Deep%20Learning/IDL3.html" class="nav-list-link">Optimizers and Regularizers (IDL3)</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Deep%20Learning/IDL4.html" class="nav-list-link">Intro to CNNs</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Deep%20Learning/IDL5.html" class="nav-list-link">Lessons Learnt 1</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/SLAM" class="nav-list-link">SLAM</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/Probability_review.html" class="nav-list-link">Recap on Probability</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/Expectation_and_cov.html" class="nav-list-link">Expectation and Covariance</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/Particle%20Filter_theory.html" class="nav-list-link">Particle Filters Theory</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/EKF.html" class="nav-list-link">EKF</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/SLAM/Non_linear_slam.html" class="nav-list-link">Least Squares SLAM</a></li></ul></li><li class="nav-list-item active"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/Vision_General" class="nav-list-link">Computer Vision</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/Computer%20Vision/camera_model.html" class="nav-list-link">Camera Models and Projections</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Computer%20Vision/Numpy.html" class="nav-list-link">Numpy for CV</a></li><li class="nav-list-item  active"><a href="http://localhost:4000/docs/Computer%20Vision/NERF.html" class="nav-list-link active">Volume Rendering and NERFs</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Computer%20Vision/bag_of_words.html" class="nav-list-link">Spatial Pyramids and Bag of Words</a></li></ul></li><li class="nav-list-item"><a href="#" class="nav-list-expander"><svg viewBox="0 0 24 24"><use xlink:href="#svg-arrow-right"></use></svg></a><a href="http://localhost:4000/docs/Vision%20with%20C++" class="nav-list-link">Computer Vision Libraries in C++</a><ul class="nav-list "><li class="nav-list-item "><a href="http://localhost:4000/docs/Vision%20with%20C++/Eigen.html" class="nav-list-link">Linear Algebra in Eigen</a></li><li class="nav-list-item "><a href="http://localhost:4000/docs/Vision%20with%20C++/Eigen_applied.html" class="nav-list-link">Eigen, OpenCV, and Images</a></li></ul></li></ul>

      
    </nav>
    <footer class="site-footer">
      This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
    </footer>
  </div>
  <div class="main" id="top">
    <div id="main-header" class="main-header">
      
        <div class="search">
          <div class="search-input-wrap">
            <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Navigating Robotics" aria-label="Search Navigating Robotics" autocomplete="off">
            <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
          </div>
          <div id="search-results" class="search-results"></div>
        </div>
      
      
      
        <nav aria-label="Auxiliary" class="aux-nav">
          <ul class="aux-nav-list">
            
              <li class="aux-nav-list-item">
                <a href="//github.com/sushanthj" class="site-button"
                  
                >
                  Sushanth Jayanth's github
                </a>
              </li>
            
          </ul>
        </nav>
      
    </div>
    <div id="main-content-wrap" class="main-content-wrap">
      
        <nav aria-label="Breadcrumb" class="breadcrumb-nav">
            <ol class="breadcrumb-nav-list">
              
                <li class="breadcrumb-nav-list-item"><a href="http://localhost:4000/docs/Vision_General">Computer Vision</a></li>
              
              <li class="breadcrumb-nav-list-item"><span>Volume Rendering and NERFs</span></li>
            </ol>
          </nav>
        
      
      <div id="main-content" class="main-content" role="main">
        
          <h1 id="introduction">
        
        
          <a href="#introduction" class="anchor-heading" aria-labelledby="introduction"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Introduction
        
        
      </h1>
    

<p>NERF gave us a whole new way of approaching general computer vision tasks like
Novel View Synthesis (NVS), 3D Reconstruction, etc. in a more physics informed way.</p>

<p>Since the formulation of rendering is crucial to understanding NERFs we’ll do that first.</p>
      <h1 id="part-1--volume-rendering">
        
        
          <a href="#part-1--volume-rendering" class="anchor-heading" aria-labelledby="part-1--volume-rendering"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Part 1 : Volume Rendering
        
        
      </h1>
    
      <h2 id="understanding-absorption-and-trasmittance">
        
        
          <a href="#understanding-absorption-and-trasmittance" class="anchor-heading" aria-labelledby="understanding-absorption-and-trasmittance"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Understanding Absorption and Trasmittance
        
        
      </h2>
    
      <h3 id="absorption-emission-model">
        
        
          <a href="#absorption-emission-model" class="anchor-heading" aria-labelledby="absorption-emission-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Absorption Emission Model
        
        
      </h3>
    

<p>Let’s consider an infinitesimal (small) volume through which we have a light ray travelling.
Now, this volume can do two things:</p>

<ul>
  <li>Absorb some intensity of incoming light</li>
  <li>Emit some light of it’s own</li>
</ul>

<p><img src="/images/Computer_Vision/NERFs/emission_absorption.png" alt="" /></p>

<p>For both cases, we see the factor <code class="language-plaintext highlighter-rouge">σ</code> this is the absorption coefficient of the volume.
Furthermore, we see that <strong>both incoming light and light produced in this volume will be
affected by this <code class="language-plaintext highlighter-rouge">σ</code></strong></p>
      <h3 id="absorption-only-model">
        
        
          <a href="#absorption-only-model" class="anchor-heading" aria-labelledby="absorption-only-model"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Absorption-only Model
        
        
      </h3>
    

<p>Modelling only absoroption through a non-homogenous volume, <strong>we derive the relationship
between incoming radiation and outgoing radiation</strong> as follows:</p>

<p><img src="/images/Computer_Vision/NERFs/transmittance_derivation.png" alt="" /></p>

<p>Note in above figure, <code class="language-plaintext highlighter-rouge">x0</code> is where the light ray enters the volume. We assume the volume
is perfectly oriented in the ray’s direction <code class="language-plaintext highlighter-rouge">ω</code>. Then <code class="language-plaintext highlighter-rouge">ωz</code> would be the length of the
volume along the <code class="language-plaintext highlighter-rouge">ω</code> unit vector. That’s why the final radiance output is <strong><code class="language-plaintext highlighter-rouge">L(x0 + ωz, ω)</code></strong></p>

<p>As you can observe, we have a new term here called <strong>Transmittance</strong>. <strong>The intuitive meaning
of transmittance is the proportion of incoming light that eventually leaves the volume (gets
transmitted).</strong></p>

<p>Think of it like absorption is a coefficient (say 0.2) meaning that 20% of all incoming light
is absorbed. For transmittance (say 0.8) the intuition would be that 80% of all light is let
through the medium.</p>
      <h3 id="why-the-importance-on-transmittance">
        
        
          <a href="#why-the-importance-on-transmittance" class="anchor-heading" aria-labelledby="why-the-importance-on-transmittance"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Why The Importance on Transmittance
        
        
      </h3>
    

<p>Trasmittance has some nice properties which simple absorption would not have. Specifically:</p>

<ul>
  <li>Monotonic Function</li>
  <li>Multiplicativity</li>
</ul>

<p>In the below picture, we see that even though <code class="language-plaintext highlighter-rouge">σ</code> might vary in the volume, the transmittance
is always a monotonic function:</p>

<p><img src="/images/Computer_Vision/NERFs/monotonic_transmittance.png" alt="" /></p>

<p>Now, previously we saw Transmittance for a non-homogenous medium. It can be easily adapted
to a homogenous medium as well as shown below:</p>

<p><img src="/images/Computer_Vision/NERFs/Homogenous_vs_non_homo.png" alt="" /></p>

<p>Now, above we see that it’s basically an exponential. The <strong>multiplicativity property of
transmittance is due to the this multiplicativity of exponentials</strong></p>

<p><img src="/images/Computer_Vision/NERFs/multiplicativity_transmittance.png" alt="" /></p>

<p>Using our transmittance terminology above, we finnaly get for <strong>absorption only transmittance</strong>:</p>

<p><img src="/images/Computer_Vision/NERFs/updated_radiance_eq.png" alt="" /></p>
      <h3 id="emission-absorption-transmittance">
        
        
          <a href="#emission-absorption-transmittance" class="anchor-heading" aria-labelledby="emission-absorption-transmittance"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Emission-Absorption Transmittance
        
        
      </h3>
    

<p>As a recap of what was done above, let’s see the basic absorption model</p>

<p><img src="/images/Computer_Vision/NERFs/transmittance_in_vacuum.png" alt="" /></p>

<p>In the above picture note the following:</p>
<ul>
  <li>The transmittance in vacuum is 1</li>
  <li>Only the cloud has some transmittance value less than 1</li>
  <li>Therefore <code class="language-plaintext highlighter-rouge">T(x,x_z) = T_cloud</code> in the above scenario</li>
</ul>

<p><strong>Now, lets make some assumptions to go from absorption only model to absorption-emission model:</strong></p>
<ul>
  <li>Let’s divide the cloud into small sections (small volumes)</li>
  <li>Let each volume not only absorb (have transmittance &lt; 1) but also be able to emit light</li>
  <li>The final radiation at the eye will be a combination of emission and absorption</li>
</ul>

<p>The context above is baked into the picture below:</p>

<p><img src="/images/Computer_Vision/NERFs/emission_absorption_vol_rendering.png" alt="" /></p>
      <h3 id="ray-marching">
        
        
          <a href="#ray-marching" class="anchor-heading" aria-labelledby="ray-marching"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Ray Marching
        
        
      </h3>
    

<p>Now, the issue with the emission-absorption model is that the integral cannot be solved numerically
without some simplifications. We will make the following simplifications:</p>

<ul>
  <li>Discretize the space into small volumes</li>
  <li>Let each small volume have it’s own <code class="language-plaintext highlighter-rouge">σ</code></li>
  <li>Our final radiation at the eye/camera will be the summation of each of these small volumes</li>
</ul>

<p><img src="/images/Computer_Vision/NERFs/ray_marching_1.png" alt="" /></p>

<p><img src="/images/Computer_Vision/NERFs/ray_marching_2.png" alt="" /></p>

<p><img src="/images/Computer_Vision/NERFs/ray_marching_3.png" alt="" /></p>

<p><img src="/images/Computer_Vision/NERFs/ray_marching_final.png" alt="" /></p>

<p>Finally, we see that computing Transmittance is recursive, where the i+1’th segment’s
transmittance <code class="language-plaintext highlighter-rouge">(T_i+1) = T(i) * T(small volume of i+1)</code></p>
      <h3 id="practice-transmittance-calculations">
        
        
          <a href="#practice-transmittance-calculations" class="anchor-heading" aria-labelledby="practice-transmittance-calculations"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Practice Transmittance Calculations
        
        
      </h3>
    

<p><img src="/images/Computer_Vision/NERFs/transmittance_question.png" alt="" /></p>

<p><img src="/images/Computer_Vision/NERFs/transmittance_solution.png" alt="" /></p>
      <h3 id="implementing-ray-marching">
        
        
          <a href="#implementing-ray-marching" class="anchor-heading" aria-labelledby="implementing-ray-marching"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementing Ray Marching
        
        
      </h3>
    

<p><strong>Stratified Sampling (discretizing into tiny volumes)</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">ray_utils</span> <span class="kn">import</span> <span class="n">RayBundle</span>
<span class="kn">from</span> <span class="nn">pytorch3d.renderer.cameras</span> <span class="kn">import</span> <span class="n">CamerasBase</span>


<span class="c1"># Sampler which implements stratified (uniform) point sampling along rays
</span><span class="k">class</span> <span class="nc">StratifiedRaysampler</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">cfg</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">n_pts_per_ray</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">.</span><span class="n">n_pts_per_ray</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">min_depth</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">.</span><span class="n">min_depth</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span> <span class="o">=</span> <span class="n">cfg</span><span class="p">.</span><span class="n">max_depth</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">ray_bundle</span><span class="p">,</span> <span class="c1"># NOTE ray_bundle is a class defined in ray_utils.py
</span>    <span class="p">):</span>
        <span class="c1"># Compute z values for self.n_pts_per_ray points uniformly sampled between [near, far]
</span>        <span class="n">z_vals</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">min_depth</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">max_depth</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_pts_per_ray</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">ray_bundle</span><span class="p">.</span><span class="n">origins</span><span class="p">.</span><span class="n">device</span><span class="p">)</span>
        <span class="c1"># z_vals.shape = (self.n_pts_per_ray,)
</span>
        <span class="c1"># Sample points from z values
</span>        <span class="s">"""
        NOTE: if image_plane_points.shape = torch.Size([65536, 3]),
              then rays_origin.shape = torch.Size([65536, 3])
              and sample_lenths.shape = torch.Size([65536, 1, 3])
        """</span>

        <span class="n">origins_expanded</span> <span class="o">=</span> <span class="n">ray_bundle</span><span class="p">.</span><span class="n">origins</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: (N, 1, 3)
</span>        <span class="n">origins_expanded</span> <span class="o">=</span> <span class="n">origins_expanded</span><span class="p">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_pts_per_ray</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: (N, D, 3)
</span>        <span class="n">directions_expanded</span> <span class="o">=</span> <span class="n">ray_bundle</span><span class="p">.</span><span class="n">directions</span><span class="p">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: (N, 1, 3)
</span>        <span class="n">directions_expanded</span> <span class="o">=</span> <span class="n">directions_expanded</span><span class="p">.</span><span class="n">expand</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">n_pts_per_ray</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: (N, D, 3)
</span>        <span class="c1"># convert z_vals to shape Shape: (1, D, 1)
</span>        <span class="n">z_vals_expanded</span> <span class="o">=</span> <span class="n">z_vals</span><span class="p">.</span><span class="n">expand</span><span class="p">(</span><span class="n">ray_bundle</span><span class="p">.</span><span class="n">origins</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">).</span><span class="n">unsqueeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Shape: (1, D, 1)
</span>
        <span class="c1"># Compute sample points
</span>        <span class="c1"># (N, D, 3) = (N, 1, 3) + (1, D, 1) * (N, 1, 3)
</span>        <span class="n">new_sample_points</span> <span class="o">=</span> <span class="n">origins_expanded</span> <span class="o">+</span> <span class="n">z_vals_expanded</span> <span class="o">*</span> <span class="n">directions_expanded</span>

        <span class="c1"># Return
</span>        <span class="k">return</span> <span class="n">ray_bundle</span><span class="p">.</span><span class="n">_replace</span><span class="p">(</span>
            <span class="n">sample_points</span><span class="o">=</span><span class="n">new_sample_points</span><span class="p">,</span>
            <span class="n">sample_lengths</span><span class="o">=</span><span class="n">z_vals_expanded</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">new_sample_points</span><span class="p">[...,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span> <span class="c1"># shape = (N, D, 1)
</span>        <span class="p">)</span>
</code></pre></div></div>

<p>Later on we’ll see that the <strong>NERF will predict the density at all sample locations for all rays</strong>.
We will use this density prediciton to find the overall transmittance and the overall color of all
rays.</p>

<p>NOTE: overall color of all rays = image</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predicted_density_for_all_samples_for_all_rays_in_chunk</span> <span class="o">=</span> <span class="n">NERF_MLP_output</span><span class="p">[</span><span class="s">'density'</span><span class="p">]</span> <span class="c1"># shape = (self._chunk_size*n_pts, 1) : The density value of that discrete volume
</span><span class="n">predicted_colors_for_all_samples_for_all_rays_in_chunk</span> <span class="o">=</span> <span class="n">NERF_MLP_output</span><span class="p">[</span><span class="s">'feature'</span><span class="p">]</span> <span class="c1"># shape = (self._chunk_size*n_pts, 3) : Emittance for each discrete volume for RGB channels
</span>
<span class="c1"># Compute length of each ray segment
# NOTE: cur_ray_bundle.sample_lengths.shape = (self._chunk_size, n_pts, n_pts)
</span><span class="n">depth_values</span> <span class="o">=</span> <span class="n">cur_ray_bundle</span><span class="p">.</span><span class="n">sample_lengths</span><span class="p">[...,</span> <span class="mi">0</span><span class="p">]</span> <span class="c1"># depth_values.shape = (self._chunk_size, n_pts)
# deltas are the distance between each sample
</span><span class="n">deltas</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">cat</span><span class="p">(</span>
    <span class="p">(</span>
        <span class="n">depth_values</span><span class="p">[...,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">-</span> <span class="n">depth_values</span><span class="p">[...,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
        <span class="mf">1e10</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">depth_values</span><span class="p">[...,</span> <span class="p">:</span><span class="mi">1</span><span class="p">]),</span>
    <span class="p">),</span>
    <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)[...,</span> <span class="bp">None</span><span class="p">]</span>

<span class="c1"># Compute aggregation weights (weights = overall transmittance for all rays in the chunk)
</span><span class="n">weights</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_compute_weights</span><span class="p">(</span>
    <span class="n">deltas</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_pts</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="c1"># shape = (self._chunk_size, n_pts, 1)
</span>    <span class="n">predicted_density_for_all_samples_for_all_rays_in_chunk</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_pts</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># shape = (self._chunk_size, n_pts, 1)
</span><span class="p">)</span>

<span class="c1"># TODO (1.5): Render (color) features using weights
# weights.shape = (self._chunk_size, n_pts, 1)
# color.shape = (self._chunk_size*n_pts, 3)
</span><span class="n">color_of_all_rays</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_aggregate</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">predicted_colors_for_all_samples_for_all_rays_in_chunk</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_pts</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span> <span class="c1"># feature = RGB color
</span>
<span class="c1"># TODO (1.5): Render depth map
# depth_values.shape = (self._chunk_size, n_pts)
</span><span class="n">depth_of_all_rays</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">_aggregate</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">depth_values</span><span class="p">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">n_pts</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Return
</span><span class="n">cur_out</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">'feature'</span><span class="p">:</span> <span class="n">color_of_all_rays</span><span class="p">,</span>
    <span class="s">'depth'</span><span class="p">:</span> <span class="n">depth_of_all_rays</span><span class="p">,</span>
<span class="p">}</span>
<span class="c1"># shape = (N, 3) for feature and (N, 1) for depth
</span></code></pre></div></div>

<p>The function <strong>compute_weights will find the overall transmittance for each ray</strong> and
<strong>compute_aggregate will use this transmittance to find either color or depth for each ray</strong></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">_compute_weights</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">deltas</span><span class="p">,</span>
        <span class="n">rays_density</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">eps</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-10</span><span class="p">):</span>
        <span class="s">"""

        Args:
            deltas : distance between each sample (self._chunk_size, n_pts, 1)
            rays_density (torch.Tensor): (self._chunk_size, n_pts, 1) predicting density values of each sample (from NERF MLP)
            eps (float, optional): Defaults to 1e-10.

        Returns:
            _type_: _description_
        """</span>
        <span class="c1"># TODO (1.5): Compute transmittance using the equation described in the README
</span>        <span class="n">num_rays</span><span class="p">,</span> <span class="n">num_sample_points</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">deltas</span><span class="p">.</span><span class="n">shape</span>
        <span class="n">transmittances</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">transmittances</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">ones</span><span class="p">((</span><span class="n">num_rays</span><span class="p">,</span> <span class="mi">1</span><span class="p">)).</span><span class="n">to</span><span class="p">(</span><span class="n">deltas</span><span class="p">.</span><span class="n">device</span><span class="p">))</span> <span class="c1"># first transmittance is 1
</span>
        <span class="c1">#! Find the transmittance for each discrete volume = T(x, x_i)
</span>        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_sample_points</span><span class="p">):</span>
            <span class="c1"># recursive formula for transmittance
</span>            <span class="n">transmittances</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">transmittances</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rays_density</span><span class="p">[:,</span> <span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">deltas</span><span class="p">[:,</span> <span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">eps</span><span class="p">))</span>

        <span class="c1">#! Find = T(x, x_t) * (1 - e^{−σ(x) * δx})
</span>        <span class="n">transmittances_stacked</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">stack</span><span class="p">(</span><span class="n">transmittances</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># the below line implements the T(x, x_t) * (1 - e^{−σ(x) * δx}) part of the equation =&gt; we'll call this 'weights'
</span>        <span class="k">return</span> <span class="n">transmittances_stacked</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">torch</span><span class="p">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">rays_density</span><span class="o">*</span><span class="n">deltas</span><span class="o">+</span><span class="n">eps</span><span class="p">))</span> <span class="c1"># -&gt; weights
</span>
    <span class="k">def</span> <span class="nf">_aggregate</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">weights</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">rays_feature</span><span class="p">:</span> <span class="n">torch</span><span class="p">.</span><span class="n">Tensor</span><span class="p">):</span>
        <span class="s">"""

        Args:
            weights (torch.Tensor): (self._chunk_size, n_pts, 1) (Overall Transmittance for each ray)
            rays_feature (torch.Tensor): (self._chunk_size*n_pts, 3) feature = color/depth

        Returns:
            feature : Final Attribute (color or depth) for each ray
        """</span>
        <span class="c1"># TODO (1.5): Aggregate (weighted sum of) features using weights
</span>        <span class="n">feature</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="nb">sum</span><span class="p">((</span><span class="n">weights</span><span class="o">*</span><span class="n">rays_feature</span><span class="p">),</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">feature</span>
</code></pre></div></div>

<p>Basically, compute_weights finds the <code class="language-plaintext highlighter-rouge">T(x, x_t) * (1 - e^{−σ(x) * δx})</code> part of the equation below:</p>

<p><img src="/images/Computer_Vision/NERFs/color.png" alt="" /></p>

<p><img src="/images/Computer_Vision/NERFs/transmittance.png" alt="" /></p>

<p>And _aggreate finds the <code class="language-plaintext highlighter-rouge">L(x,ω)</code> which can be color or depth for each ray</p>
      <h3 id="next-steps-from-ray-marching">
        
        
          <a href="#next-steps-from-ray-marching" class="anchor-heading" aria-labelledby="next-steps-from-ray-marching"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Next Steps from Ray Marching
        
        
      </h3>
    

<p>As you saw above, we need to predict two things:</p>
<ul>
  <li>The density of each small volume sample</li>
  <li>The color of each small volume sample</li>
</ul>

<p>Therefore, if we discretize volume into 10 small volumes, we will need to predict:</p>
<ul>
  <li>(10,3) colors where 3 is for RGB</li>
  <li>(10,1) densities for each of the small volumes</li>
</ul>

<p>This prediction will be done by NERF!</p>

        

        

        
        
          <hr>
          <footer>
            

            <p class="text-small text-grey-dk-100 mb-0"></p>

            
              <div class="d-flex mt-2">
                
                
              </div>
            
          </footer>
        

      </div>
    </div>

    
      

      <div class="search-overlay"></div>
    
  </div>
</body>
</html>

