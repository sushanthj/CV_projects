

<!DOCTYPE html>

<html lang="en-US">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  <link rel="stylesheet" href="/assets/css/just-the-docs-default.css">

  <link rel="stylesheet" href="/assets/css/just-the-docs-head-nav.css" id="jtd-head-nav-stylesheet">

  <style id="jtd-nav-activation">
  

    .site-nav > ul.nav-list:first-child > li > a,
    
    .site-nav > ul.nav-list:first-child > li > ul > li:not(:nth-child(5)) > a,
    .site-nav > ul.nav-list:first-child > li > ul > li > ul > li a {
      background-image: none;
    }

    .site-nav > ul.nav-list:not(:first-child) a,
    .site-nav li.external a {
      background-image: none;
    }

    .site-nav > ul.nav-list:first-child > li:nth-child(8) > ul > li:nth-child(5) > a {
      font-weight: 600;
      text-decoration: none;
    }.site-nav > ul.nav-list:first-child > li:nth-child(8) > button svg,
    .site-nav > ul.nav-list:first-child > li:nth-child(8) > ul > li:nth-child(5) > button svg {
      transform: rotate(-90deg);
    }.site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(8) > ul.nav-list,
    .site-nav > ul.nav-list:first-child > li.nav-list-item:nth-child(8) > ul.nav-list > li.nav-list-item:nth-child(5) > ul.nav-list {
      display: block;
    }
  </style>

  
    
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-0VNMB6VPJF"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      
        gtag('config', 'G-0VNMB6VPJF', { 'anonymize_ip': true });
      
    </script>
  

  
    <script src="/assets/js/vendor/lunr.min.js"></script>
  

  <script src="/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">

  



  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Optimizers and Regularizers (IDL3) | Navigating Robotics</title>
<meta name="generator" content="Jekyll v3.10.0" />
<meta property="og:title" content="Optimizers and Regularizers (IDL3)" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Projects and assignments during my time in CMU" />
<meta property="og:description" content="Projects and assignments during my time in CMU" />
<link rel="canonical" href="http://localhost:4000/docs/Deep%20Learning/IDL3.html" />
<meta property="og:url" content="http://localhost:4000/docs/Deep%20Learning/IDL3.html" />
<meta property="og:site_name" content="Navigating Robotics" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Optimizers and Regularizers (IDL3)" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","description":"Projects and assignments during my time in CMU","headline":"Optimizers and Regularizers (IDL3)","url":"http://localhost:4000/docs/Deep%20Learning/IDL3.html"}</script>
<!-- End Jekyll SEO tag -->


  

</head>

<body>
  <a class="skip-to-main" href="#main-content">Skip to main content</a>
  <svg xmlns="http://www.w3.org/2000/svg" class="d-none">
  <symbol id="svg-link" viewBox="0 0 24 24">
  <title>Link</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-link">
    <path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path>
  </svg>
</symbol>

  <symbol id="svg-menu" viewBox="0 0 24 24">
  <title>Menu</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu">
    <line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line>
  </svg>
</symbol>

  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
  <title>Expand</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-chevron-right">
    <polyline points="9 18 15 12 9 6"></polyline>
  </svg>
</symbol>

  <!-- Feather. MIT License: https://github.com/feathericons/feather/blob/master/LICENSE -->
<symbol id="svg-external-link" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-external-link">
  <title id="svg-external-link-title">(external link)</title>
  <path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path><polyline points="15 3 21 3 21 9"></polyline><line x1="10" y1="14" x2="21" y2="3"></line>
</symbol>

  
    <symbol id="svg-doc" viewBox="0 0 24 24">
  <title>Document</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file">
    <path d="M13 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V9z"></path><polyline points="13 2 13 9 20 9"></polyline>
  </svg>
</symbol>

    <symbol id="svg-search" viewBox="0 0 24 24">
  <title>Search</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-search">
    <circle cx="11" cy="11" r="8"></circle><line x1="21" y1="21" x2="16.65" y2="16.65"></line>
  </svg>
</symbol>

  
  
    <!-- Bootstrap Icons. MIT License: https://github.com/twbs/icons/blob/main/LICENSE.md -->
<symbol id="svg-copy" viewBox="0 0 16 16">
  <title>Copy</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16">
    <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/>
    <path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/>
  </svg>
</symbol>
<symbol id="svg-copied" viewBox="0 0 16 16">
  <title>Copied</title>
  <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-clipboard-check-fill" viewBox="0 0 16 16">
    <path d="M6.5 0A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3Zm3 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3Z"/>
    <path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1A2.5 2.5 0 0 1 9.5 5h-3A2.5 2.5 0 0 1 4 2.5v-1Zm6.854 7.354-3 3a.5.5 0 0 1-.708 0l-1.5-1.5a.5.5 0 0 1 .708-.708L7.5 10.793l2.646-2.647a.5.5 0 0 1 .708.708Z"/>
  </svg>
</symbol>

  
</svg>

  
    <div class="side-bar">
  <div class="site-header" role="banner">
    <a href="/" class="site-title lh-tight">
  Navigating Robotics

</a>
    <button id="menu-button" class="site-button btn-reset" aria-label="Toggle menu" aria-pressed="false">
      <svg viewBox="0 0 24 24" class="icon" aria-hidden="true"><use xlink:href="#svg-menu"></use></svg>
    </button>
  </div>

  <nav aria-label="Main" id="site-nav" class="site-nav">
  
  
    <ul class="nav-list"><li class="nav-list-item"><a href="/" class="nav-list-link">Home</a></li><li class="nav-list-item"><a href="/intro/" class="nav-list-link">Building this Page</a></li><li class="nav-list-item"><a href="/planar_homography/" class="nav-list-link">Planar Homography</a></li><li class="nav-list-item"><a href="/3D_reconstruction/" class="nav-list-link">3D Reconstruction</a></li><li class="nav-list-item"><a href="/constr_rrt/" class="nav-list-link">Constrained RRT</a></li><li class="nav-list-item"><a href="/ConvNext/" class="nav-list-link">ConvNext</a></li><li class="nav-list-item"><a href="/mrsd_proj/" class="nav-list-link">MRSD Capstone Project</a></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Deep Learning category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/docs/Deep%20Learning" class="nav-list-link">Deep Learning</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/Deep%20Learning/Basics.html" class="nav-list-link">ML Basics</a></li><li class="nav-list-item"><a href="/docs/Deep%20Learning/DL.html" class="nav-list-link">Deep Learning Starter</a></li><li class="nav-list-item"><a href="/docs/Deep%20Learning/IDL1.html" class="nav-list-link">MLPs (IDL1)</a></li><li class="nav-list-item"><a href="/docs/Deep%20Learning/IDL2.html" class="nav-list-link">Classifiers (IDL2)</a></li><li class="nav-list-item"><a href="/docs/Deep%20Learning/IDL3.html" class="nav-list-link">Optimizers and Regularizers (IDL3)</a></li><li class="nav-list-item"><a href="/docs/Deep%20Learning/IDL4.html" class="nav-list-link">Intro to CNNs</a></li><li class="nav-list-item"><a href="/docs/Deep%20Learning/IDL5.html" class="nav-list-link">Lessons Learnt 1</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in SLAM category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/docs/SLAM" class="nav-list-link">SLAM</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/SLAM/Probability_review.html" class="nav-list-link">Recap on Probability</a></li><li class="nav-list-item"><a href="/docs/SLAM/Expectation_and_cov.html" class="nav-list-link">Expectation and Covariance</a></li><li class="nav-list-item"><a href="/docs/SLAM/Particle%20Filter_theory.html" class="nav-list-link">Particle Filters Theory</a></li><li class="nav-list-item"><a href="/docs/SLAM/EKF.html" class="nav-list-link">EKF</a></li><li class="nav-list-item"><a href="/docs/SLAM/Non_linear_slam.html" class="nav-list-link">Least Squares SLAM</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Computer Vision category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/docs/Vision_General" class="nav-list-link">Computer Vision</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/Computer%20Vision/camera_model.html" class="nav-list-link">Camera Models and Projections</a></li><li class="nav-list-item"><a href="/docs/Computer%20Vision/Numpy.html" class="nav-list-link">Numpy for CV</a></li><li class="nav-list-item"><a href="/docs/Computer%20Vision/NERF.html" class="nav-list-link">Volume Rendering and NERFs</a></li><li class="nav-list-item"><a href="/docs/Computer%20Vision/bag_of_words.html" class="nav-list-link">Spatial Pyramids and Bag of Words</a></li><li class="nav-list-item"><a href="/docs/Computer%20Vision/Optical%20Flow.html" class="nav-list-link">Optical Flow and Image Alignment</a></li></ul></li><li class="nav-list-item"><button class="nav-list-expander btn-reset" aria-label="toggle items in Computer Vision Libraries in C++ category" aria-pressed="false">
        <svg viewBox="0 0 24 24" aria-hidden="true"><use xlink:href="#svg-arrow-right"></use></svg>
      </button><a href="/docs/Vision%20with%20C++" class="nav-list-link">Computer Vision Libraries in C++</a><ul class="nav-list"><li class="nav-list-item"><a href="/docs/Vision%20with%20C++/Eigen.html" class="nav-list-link">Linear Algebra in Eigen</a></li><li class="nav-list-item"><a href="/docs/Vision%20with%20C++/Eigen_applied.html" class="nav-list-link">Eigen, OpenCV, and Images</a></li></ul></li><li class="nav-list-item"><a href="/markdown-cheat-sheet.html" class="nav-list-link">Markdown Cheat Sheet</a></li></ul>
  
</nav>




  
  
    <footer class="site-footer">
      This site uses <a href="https://github.com/just-the-docs/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.
    </footer>
  
</div>

  
  <div class="main" id="top">
    <div id="main-header" class="main-header">
  
    

<div class="search" role="search">
  <div class="search-input-wrap">
    <input type="text" id="search-input" class="search-input" tabindex="0" placeholder="Search Navigating Robotics" aria-label="Search Navigating Robotics" autocomplete="off">
    <label for="search-input" class="search-label"><svg viewBox="0 0 24 24" class="search-icon"><use xlink:href="#svg-search"></use></svg></label>
  </div>
  <div id="search-results" class="search-results"></div>
</div>

  
  
  
    <nav aria-label="Auxiliary" class="aux-nav">
  <ul class="aux-nav-list">
    
      <li class="aux-nav-list-item">
        <a href="//github.com/sushanthj" class="site-button"
          
        >
          Sushanth Jayanth's github
        </a>
      </li>
    
  </ul>
</nav>

  
</div>

    <div class="main-content-wrap">
      <nav aria-label="Breadcrumb" class="breadcrumb-nav">
  <ol class="breadcrumb-nav-list">
    <li class="breadcrumb-nav-list-item"><a href="/docs/Deep%20Learning">Deep Learning</a></li>
    <li class="breadcrumb-nav-list-item"><span>Optimizers and Regularizers (IDL3)</span></li>
  </ol>
</nav>


      <div id="main-content" class="main-content">
        <main>
          
            <details open="">
  <summary>
    Table of contents
  {: .text-delta }
  </summary>
<ol id="markdown-toc">
  <li><a href="#before-you-begin" id="markdown-toc-before-you-begin">Before you Begin</a></li>
  <li><a href="#improving-over-momentum-update" id="markdown-toc-improving-over-momentum-update">Improving over momentum update</a>    <ol>
      <li><a href="#commonly-used-methods-which-use-second-moment" id="markdown-toc-commonly-used-methods-which-use-second-moment">Commonly Used methods which use Second Moment</a>        <ol>
          <li><a href="#rms-prop" id="markdown-toc-rms-prop">RMS Prop</a></li>
          <li><a href="#adam-rmsprop-with-momentum" id="markdown-toc-adam-rmsprop-with-momentum">ADAM (RMSprop with momentum)</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#batch-normalization" id="markdown-toc-batch-normalization">Batch Normalization</a>    <ol>
      <li><a href="#problem-with-covarite-shifts" id="markdown-toc-problem-with-covarite-shifts">Problem with covarite shifts</a></li>
      <li><a href="#solution-to-covariate-shifts" id="markdown-toc-solution-to-covariate-shifts">Solution to covariate shifts</a></li>
      <li><a href="#batch-norm-theory" id="markdown-toc-batch-norm-theory">Batch Norm Theory</a></li>
      <li><a href="#backprop-through-batch-norm" id="markdown-toc-backprop-through-batch-norm">Backprop through Batch Norm</a>        <ol>
          <li><a href="#derivation" id="markdown-toc-derivation">Derivation</a></li>
        </ol>
      </li>
      <li><a href="#batch-norm-in-test-time" id="markdown-toc-batch-norm-in-test-time">Batch Norm in Test Time</a></li>
    </ol>
  </li>
  <li><a href="#overfitting" id="markdown-toc-overfitting">Overfitting</a>    <ol>
      <li><a href="#smoothness-through-weight-manipulation" id="markdown-toc-smoothness-through-weight-manipulation">Smoothness through weight manipulation</a></li>
      <li><a href="#smoothness-through-weight-constraints-regularization" id="markdown-toc-smoothness-through-weight-constraints-regularization">Smoothness through weight constraints (Regularization)</a></li>
      <li><a href="#smoothness-through-network-structure" id="markdown-toc-smoothness-through-network-structure">Smoothness through network structure</a>        <ol>
          <li><a href="#example-for-further-clarity" id="markdown-toc-example-for-further-clarity">Example for further clarity</a></li>
        </ol>
      </li>
      <li><a href="#dropout" id="markdown-toc-dropout">Dropout</a>        <ol>
          <li><a href="#implementing-dropout-during-training" id="markdown-toc-implementing-dropout-during-training">Implementing Dropout during Training</a></li>
          <li><a href="#implementing-dropout-during-inference" id="markdown-toc-implementing-dropout-during-inference">Implementing Dropout during Inference</a></li>
        </ol>
      </li>
    </ol>
  </li>
  <li><a href="#augmentation" id="markdown-toc-augmentation">Augmentation</a></li>
  <li><a href="#other-tricks" id="markdown-toc-other-tricks">Other Tricks</a></li>
</ol>

</details>
<h2 id="before-you-begin">
  
  
    <a href="#before-you-begin" class="anchor-heading" aria-labelledby="before-you-begin"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Before you Begin
  
  
</h2>
    

<p><a href="https://www.youtube.com/watch?v=fMie0uWwzDQ&amp;list=PLp-0K3kfddPzCnS4CqKphh-zT3aDwybDe&amp;index=15&amp;ab_channel=CarnegieMellonUniversityDeepLearning" class="btn fs-3 mb-4 mb-md-0">Ref: 11-785</a></p>
<h1 id="improving-over-momentum-update">
  
  
    <a href="#improving-over-momentum-update" class="anchor-heading" aria-labelledby="improving-over-momentum-update"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Improving over momentum update
  
  
</h1>
    

<p>Previously we saw how the derivatives change in subsequent steps (as we did in simple
momentum) and take a step considering the weighted average of the current and prior step
(actual implementation was a running average)</p>

<p>Now, we’ll consider the way in which these derivatives change (this is called second moment)
which takes care of the variance in graident shifts.</p>

<p><img src="/images/IDL3/momentum1.png" alt="" /></p>

<p>The second moment can be implemented as shown below. As seen in our prior image, since we had
high variation along y and low variation along x, we will do:</p>

<p><img src="/images/IDL3/momentum2.png" alt="" /></p>
<h2 id="commonly-used-methods-which-use-second-moment">
  
  
    <a href="#commonly-used-methods-which-use-second-moment" class="anchor-heading" aria-labelledby="commonly-used-methods-which-use-second-moment"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Commonly Used methods which use Second Moment
  
  
</h2>
    
<h3 id="rms-prop">
  
  
    <a href="#rms-prop" class="anchor-heading" aria-labelledby="rms-prop"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> RMS Prop
  
  
</h3>
    

<p>Here, let’s do a running average like simple momentum, but do it on the second derivative
of the gradient. The gamma value is just a weighting factor between prior step’s gradient (k-1)
and (1-gamma) is the weight applied to the current step’s gradient:</p>

<p><img src="/images/IDL3/rmsprop1.png" alt="" /></p>

<p>Now, the way we will include this is our update will be to normalize the learning rate using
this second second moement:</p>

<p><img src="/images/IDL3/rmsprop2.png" alt="" /></p>

<p>Just for comparison, this is how the update step for simple momentum only scaled the preious
step’s weight magnitude and did not touch learning rate.</p>

<p><img src="/images/IDL2/Convergence16.png" alt="" /></p>
<h3 id="adam-rmsprop-with-momentum">
  
  
    <a href="#adam-rmsprop-with-momentum" class="anchor-heading" aria-labelledby="adam-rmsprop-with-momentum"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> ADAM (RMSprop with momentum)
  
  
</h3>
    

<p><img src="/images/IDL3/adam1.png" alt="" /></p>

<p>The reason first and second moments are scaled by the weighting factor is to ensure that
in the beginning of training, we don’t let sigma and gamma terms to dominate 
(it’ll slow us down)</p>

<p><img src="/images/IDL3/adam3.png" alt="" /></p>
<h1 id="batch-normalization">
  
  
    <a href="#batch-normalization" class="anchor-heading" aria-labelledby="batch-normalization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Batch Normalization
  
  
</h1>
    
<h3 id="problem-with-covarite-shifts">
  
  
    <a href="#problem-with-covarite-shifts" class="anchor-heading" aria-labelledby="problem-with-covarite-shifts"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Problem with covarite shifts
  
  
</h3>
    

<p><img src="/images/IDL3/covshfit1.png" alt="" /></p>

<p><img src="/images/IDL3/covshift2.png" alt="" /></p>
<h3 id="solution-to-covariate-shifts">
  
  
    <a href="#solution-to-covariate-shifts" class="anchor-heading" aria-labelledby="solution-to-covariate-shifts"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Solution to covariate shifts
  
  
</h3>
    

<p><img src="/images/IDL3/covshift3.png" alt="" /></p>
<h2 id="batch-norm-theory">
  
  
    <a href="#batch-norm-theory" class="anchor-heading" aria-labelledby="batch-norm-theory"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Batch Norm Theory
  
  
</h2>
    

<ul>
  <li>We do this covariate shifts typically at the at location of the affine sum (Wx + b)</li>
  <li><img src="/images/IDL3/batch_norm1.png" alt="" /></li>
  <li><img src="/images/IDL3/batch_norm2.png" alt="" /></li>
  <li>The above step (first yellow box) will cause all training instances to have mean = 0 and variance = 1</li>
  <li>Now, we move the entire data to a separate appropriate location (second yellow box)
as defined by gamma and beta.</li>
  <li>How do we get this gamma and beta?
    <ul>
      <li>Ans. They are only learnt, we don’t define or derive them (initialize them to 0 or 1 and 
let them be learned)</li>
      <li><img src="/images/IDL4/batch_norm_extra.png" alt="" /></li>
    </ul>
  </li>
</ul>

<p>Q. Why is batch_norm applied before the activation function?
Ans. It’s debatable. But if it’s used after activation some activations may get
reveresed maybe?</p>

<p>Note. Understand vocab: Difference between Normalization and Standardization</p>

<p><img src="/images/IDL4/norm_v_stand.png" alt="" /></p>

<p>Now, its nice to see data having low variance. However, the real issue arises when we try
to do backprop.</p>
<h2 id="backprop-through-batch-norm">
  
  
    <a href="#backprop-through-batch-norm" class="anchor-heading" aria-labelledby="backprop-through-batch-norm"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Backprop through Batch Norm
  
  
</h2>
    

<p>Conventional backprop happens by taking a derivative of the divergence function as shown below:</p>

<p><img src="/images/IDL3/batch_norm3.png" alt="" /></p>

<p><strong>However, after batch norm, it gets tricky since our divergence will now depend on 
not only the mini-batch (training samples of mini-batch), but will now also depend on
the mean and variance of the entire mini-batch (since our mini-batch was scaled and shifted
according to the mean and variance)</strong></p>

<p><img src="/images/IDL3/batch_norm4.png" alt="" /></p>

<p><img src="/images/IDL3/batch_norm6.png" alt="" /></p>

<p><img src="/images/IDL3/batch_norm5.png" alt="" /></p>
<h3 id="derivation">
  
  
    <a href="#derivation" class="anchor-heading" aria-labelledby="derivation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Derivation
  
  
</h3>
    

<p>The derivation is shown below:</p>

<p><img src="/images/IDL3/bbatch1.jpg" alt="" />
<img src="/images/IDL3/bbatch2.jpg" alt="" />
<img src="/images/IDL3/bbatch3.jpg" alt="" />
<img src="/images/IDL3/bbatch4.jpg" alt="" />
<img src="/images/IDL3/bbatch5.jpg" alt="" />
<img src="/images/IDL3/bbatch6.jpg" alt="" />
<img src="/images/IDL3/bbatch7.jpg" alt="" />
<img src="/images/IDL3/bbatch8.jpg" alt="" />
<img src="/images/IDL3/bbatch9.jpg" alt="" /></p>
<h2 id="batch-norm-in-test-time">
  
  
    <a href="#batch-norm-in-test-time" class="anchor-heading" aria-labelledby="batch-norm-in-test-time"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Batch Norm in Test Time
  
  
</h2>
    

<p>Here also we need some estimate of variance as to where this test image belongs to.
We do so by using a running average over the training batches.</p>

<p><img src="/images/IDL3/batch_norm7.png" alt="" /></p>
<h1 id="overfitting">
  
  
    <a href="#overfitting" class="anchor-heading" aria-labelledby="overfitting"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Overfitting
  
  
</h1>
    

<p><img src="/images/IDL3/ofit1.png" alt="" /></p>

<p>We essentially need a way to smoothen the above curve such that it fills in the gap nicely.</p>

<p>There are several ways of doing this, but the most common ones are:</p>
<h2 id="smoothness-through-weight-manipulation">
  
  
    <a href="#smoothness-through-weight-manipulation" class="anchor-heading" aria-labelledby="smoothness-through-weight-manipulation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Smoothness through weight manipulation
  
  
</h2>
    

<p>Think of the sigmoid function <br />
<img src="/images/IDL3/ofit2.png" alt="" /></p>

<p>Now, if the value of our input (x) increases a lot, the curve changes from a nice
smooth curve to something a lot more steep:</p>

<p><img src="/images/IDL3/ofit3.png" alt="" />
(here w = our input (x))</p>

<p><strong>Therefore simply constraining the weight to be low will ensure the perceptron output is
smooth.</strong></p>
<h2 id="smoothness-through-weight-constraints-regularization">
  
  
    <a href="#smoothness-through-weight-constraints-regularization" class="anchor-heading" aria-labelledby="smoothness-through-weight-constraints-regularization"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Smoothness through weight constraints (Regularization)
  
  
</h2>
    

<p>This is basically regularization (where we ensure model is penalized for large weights)</p>

<p><img src="/images/IDL3/ofit4.png" alt="" /></p>

<p>Now, this is also easy to backprop as shown below:</p>

<p><img src="/images/IDL3/ofit5.png" alt="" /></p>
<h2 id="smoothness-through-network-structure">
  
  
    <a href="#smoothness-through-network-structure" class="anchor-heading" aria-labelledby="smoothness-through-network-structure"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Smoothness through network structure
  
  
</h2>
    

<ul>
  <li>
    <p>As we saw in the MLP section on why depth matters, each layer of an MLP imposes
constraints, i.e. each layer creates some decision boundary.</p>
  </li>
  <li>
    <p>See <a href="https://sush-vision-projects.herokuapp.com/docs/DL_Overview/IDL1.html#why-do-we-need-depth">why we need depth</a></p>
  </li>
  <li>
    <p>In the picture below, after the first layer, we know that our input is in either
a pentagon region of a triangle region (<strong>but we don’t know where inside it!</strong>)</p>
  </li>
  <li>
    <p><img src="/images/IDL3/ofit6.png" alt="" /></p>
  </li>
  <li>
    <p>Therefore, deeper models have a natural tendency to restricting shapes they can model
and this gives the natural smoothness required.</p>
  </li>
</ul>
<h3 id="example-for-further-clarity">
  
  
    <a href="#example-for-further-clarity" class="anchor-heading" aria-labelledby="example-for-further-clarity"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Example for further clarity
  
  
</h3>
    

<p><img src="/images/IDL3/ofit7.png" alt="" /></p>

<p>In the above example, the earlier layers have really bad fit shapes. As we go deeper
the smoothness naturally increased.</p>
<h2 id="dropout">
  
  
    <a href="#dropout" class="anchor-heading" aria-labelledby="dropout"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Dropout
  
  
</h2>
    

<ul>
  <li>
    <p>During Train time, each neuron is active such that: <br />
(number_of_instances_neuron_is_active/total_number_of_instances) = alpha</p>

    <p>i.e. if the chance of a neuron being active is say 0.7 (then alpha = 0.7)</p>
  </li>
  <li>
    <p><img src="/images/IDL3/ofit9.png" alt="" /></p>
  </li>
  <li>
    <p><strong>By following above steps, The effective network is different for different sets of inputs.
Additionally, the graidents are also updated differently</strong></p>
  </li>
  <li>
    <p>Like any Bernoulli Distribution, each event has 2 outcomes. Therefore a statistical 
interpretation would yield the below picture:</p>
  </li>
  <li>
    <p><img src="/images/IDL3/ofit10.png" alt="" /></p>
  </li>
  <li>
    <p>I think it also serves as a form of augmentation, where instead of blacking out certain
parts of the image, we make the object recognizable only at certain receptive fields</p>
  </li>
  <li>
    <p>Dropout also has the tendency of removing redundancies in learning. i.e. the network 
learns a cat even if it doesn’t have a tail, or if it doens’t have pointy ears</p>
  </li>
</ul>
<h3 id="implementing-dropout-during-training">
  
  
    <a href="#implementing-dropout-during-training" class="anchor-heading" aria-labelledby="implementing-dropout-during-training"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementing Dropout during Training
  
  
</h3>
    

<p>The dropout is added onto the activation layer as an additional (like an if condition) constraint. It is shown below</p>

<p><img src="/images/IDL3/ofit11.png" alt="" /></p>

<p><strong>Now, we will use this alpha value in our test time everywhere</strong></p>
<h3 id="implementing-dropout-during-inference">
  
  
    <a href="#implementing-dropout-during-inference" class="anchor-heading" aria-labelledby="implementing-dropout-during-inference"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Implementing Dropout during Inference
  
  
</h3>
    

<ol>
  <li>We could add alpha (the bernoulli factor) to the activation of every neuron (just like train time)</li>
  <li>Or we could mulltiply every weight with alpha (we will effectively be blocking out connections instead of neurons)</li>
  <li><strong>Instead of applying alpha as chance of a neuron being active during train time, use
inverse of alpha. Then during test time, we just don’t use alpha at all!!</strong></li>
</ol>

<p><img src="/images/IDL3/ofit13.png" alt="" /></p>
<h1 id="augmentation">
  
  
    <a href="#augmentation" class="anchor-heading" aria-labelledby="augmentation"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Augmentation
  
  
</h1>
    

<ol>
  <li>Mosaicing</li>
  <li>Flipping</li>
  <li>Rotating</li>
  <li>Blurring</li>
  <li>Warp (Distort the image)</li>
</ol>
<h1 id="other-tricks">
  
  
    <a href="#other-tricks" class="anchor-heading" aria-labelledby="other-tricks"><svg viewBox="0 0 16 16" aria-hidden="true"><use xlink:href="#svg-link"></use></svg></a> Other Tricks
  
  
</h1>
    
<ol>
  <li>Normalize the input (covariate shifts in next section)</li>
  <li>Xavier Initialization</li>
</ol>

          

          
            
          
        </main>
        

  <hr>
  <footer>
    

    <p class="text-small text-grey-dk-100 mb-0"></p>

    
      <div class="d-flex mt-2">
        
        
      </div>
    
  </footer>


      </div>
    </div>
    
      

<div class="search-overlay"></div>

    
  </div>

  
</body>
</html>

